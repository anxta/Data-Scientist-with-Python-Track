{"cells":[{"source":"# Data Manipulation with Pandas\n","metadata":{},"cell_type":"markdown","id":"33ecb3c6-5f40-4423-a117-53e09c21b523"},{"source":"# Import the course packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Import the four datasets\navocado = pd.read_csv(\"datasets/avocado.csv\")\nhomelessness = pd.read_csv(\"datasets/homelessness.csv\")\ntemperatures = pd.read_csv(\"datasets/temperatures.csv\")\nwalmart = pd.read_csv(\"datasets/walmart.csv\")","metadata":{"scrolled":true,"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"executionCancelledAt":null,"executionTime":35,"lastExecutedAt":1693009380475,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the course packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Import the four datasets\navocado = pd.read_csv(\"datasets/avocado.csv\")\nhomelessness = pd.read_csv(\"datasets/homelessness.csv\")\ntemperatures = pd.read_csv(\"datasets/temperatures.csv\")\nwalmart = pd.read_csv(\"datasets/walmart.csv\")"},"id":"2e25fdd8-4d84-45bc-80f0-949917e00a17","cell_type":"code","execution_count":3,"outputs":[]},{"source":"# Aggregating DataFrames","metadata":{},"cell_type":"markdown","id":"9d4362f5-b7e3-4d27-8d8f-ed1e7a1aefb7"},{"source":"**Maximun and minuum**","metadata":{},"id":"e9a448e0","cell_type":"markdown"},{"source":"# Add your code snippets here\n# Print the maximum of the date column\nprint(sales[\"date\"].max())\n\n# Print the minimum of the date column\nprint(sales[\"date\"].min())","metadata":{"executionCancelledAt":null,"executionTime":9,"lastExecutedAt":1700244461613,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"id":"893055c9","cell_type":"code","execution_count":0,"outputs":[]},{"source":"**Efficient summaries agg**","metadata":{},"cell_type":"markdown","id":"b2e7d15e-0afa-4d26-b45d-e4d4a70d6d75"},{"source":"\"\"\"The .agg() method allows you to apply your own custom functions to a DataFrame, as well as apply functions to more than one column of a DataFrame at once, making your aggregations super-efficient. For example\"\"\"\n\ndf['column'].agg(function)\n\n# EXAMPLE\n# A custom IQR function\ndef iqr(column):\n    return column.quantile(0.75) - column.quantile(0.25)\n\n# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\nprint(sales[[\"temperature_c\", \"fuel_price_usd_per_l\",\"unemployment\"]].agg(iqr))","metadata":{},"cell_type":"code","id":"4b90566c-d022-4e60-81f5-1baf5ba919c4","execution_count":null,"outputs":[]},{"source":"**Cumulative statistics**","metadata":{},"cell_type":"markdown","id":"611219e3-1104-4800-82c7-bf019d117a06"},{"source":"# Sort sales_1_1 by date\nsales_1_1 = sales_1_1.sort_values(\"date\")\n\n# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\nsales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n\n# Get the cumulative max of weekly_sales, add as cum_max_sales col\nsales_1_1[\"cum_max_sales\"]= sales_1_1[\"weekly_sales\"].cummax()\n\n# See the columns you calculated\nprint(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])","metadata":{"executionCancelledAt":null,"executionTime":145,"lastExecutedAt":1700244452026,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"cell_type":"code","id":"3ecf731d-f322-475c-ad96-84fca235bffb","execution_count":0,"outputs":[]},{"source":"**Droppping duplicates**","metadata":{},"cell_type":"markdown","id":"312ecefe-fbed-44d8-b45f-0a614882c807"},{"source":"# Drop duplicate store/department combinations\nstore_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n\nprint(store_depts.head())\n\n# Subset the rows where is_holiday is True and drop duplicate in dates\nholiday_dates = (sales[sales[\"is_holiday\"] == True]).drop_duplicates(subset= \"date\")\n\n# Print date col of holiday_dates\nprint(holiday_dates[\"date\"])\n","metadata":{},"cell_type":"code","id":"449097e5-7605-4803-a4e6-5f855e5e8dbc","execution_count":null,"outputs":[]},{"source":"**Counting Categorical Values**\n","metadata":{},"cell_type":"markdown","id":"06dda781-2ba7-45cf-b3c4-4c882ec501b2"},{"source":"# Count the number of stores of each type\nstore_counts = store_types[\"type\"].value_counts()\nprint(store_counts)\n\n# Get the proportion of stores of each type\nstore_props =store_types[\"type\"].value_counts(normalize= True)\nprint(store_props)\n\n# Count the number of each department number and sort\ndept_counts_sorted =store_depts[\"department\"].value_counts(sort=True)\nprint(dept_counts_sorted)\n\n# Get the proportion of departments of each number and sort\ndept_props_sorted = store_depts[\"department\"].value_counts(sort= True, normalize=True)\nprint(dept_props_sorted)","metadata":{},"cell_type":"code","id":"ea0d05fa-3bda-404c-8ea3-d46e9e28f85c","execution_count":null,"outputs":[]},{"source":"**Group by**","metadata":{},"cell_type":"markdown","id":"933c4c6a-7369-42d2-91bd-9615e1995d15"},{"source":"# From previous step\nsales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n\n# Group by type and is_holiday; calc total weekly sales\nsales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\nprint(sales_by_type_is_holiday)","metadata":{},"cell_type":"code","id":"3c61ef8f-b6e4-4ecc-8f57-eb66b954bb02","execution_count":null,"outputs":[]},{"source":"**Median, mean**","metadata":{},"cell_type":"markdown","id":"2143d6bd-c11f-46a0-bf26-39d5d2ffa240"},{"source":"# Import numpy with the alias np\nimport numpy as np\n\n# For each store type, aggregate weekly_sales: get min, max, mean, and #median\nsales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg(\n   [np.min, np.max, np.mean , np.median])\n\n# Print sales_stats\nprint(sales_stats)\n\n# For each store type, aggregate unemployment and fuel_price_usd_per_l: # get min, max, mean, and median\nunemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean , np.median])\n\n# Print unemp_fuel_stats\nprint(unemp_fuel_stats)","metadata":{},"cell_type":"code","id":"19d59964-9add-44fd-ab6f-bfe54778022c","execution_count":null,"outputs":[]},{"source":"### Pivot Tables","metadata":{},"cell_type":"markdown","id":"30daf354-5628-4045-b63f-215804d9e700"},{"source":"#In pandas, pivot tables are essentially another way of performing grouped calculations. That is, the .pivot_table() method is an alternative to .groupby().\n\n# Pivot for mean weekly_sales for each store type\nmean_sales_by_type = sales.pivot_table(values= \"weekly_sales\", index=\"type\")\n\n# Print mean_sales_by_type\nprint(mean_sales_by_type)","metadata":{},"cell_type":"code","id":"99d84465-da71-4f2f-a278-2ae8b5261006","execution_count":null,"outputs":[]},{"source":"_mean and median_","metadata":{},"cell_type":"markdown","id":"081aa6ed-77fd-4565-abed-a6dc1864cd27"},{"source":"# Import NumPy as np\nimport numpy as np\n\n# Pivot for mean and median weekly_sales for each store type\nmean_med_sales_by_type = sales.pivot_table(values= \"weekly_sales\", index= \"type\", aggfunc= [np.mean, np.median])\n\n# Print mean_med_sales_by_type\nprint(mean_med_sales_by_type)\n\n#si fuera una sola aggfunction= np.----","metadata":{},"cell_type":"code","id":"95040cb0-afdf-44a7-8955-ec96d5b15144","execution_count":null,"outputs":[]},{"source":"_columns=_","metadata":{},"cell_type":"markdown","id":"c25c9d69-afa4-4b1d-9b94-b8b9d9b50367"},{"source":"# Pivot for mean weekly_sales by store type and holiday \nmean_sales_by_type_holiday = sales.pivot_table(values= \"weekly_sales\", index=  \"type\", columns= \"is_holiday\")\n\n# Print mean_sales_by_type_holiday\nprint(mean_sales_by_type_holiday)","metadata":{},"cell_type":"code","id":"e662ea6b-59d8-49d5-9080-ef27b460c99d","execution_count":null,"outputs":[]},{"source":"# Print mean weekly_sales by department and type; fill missing values with 0\nprint(sales.pivot_table(values=\"weekly_sales\", index=\"type\", \ncolumns= \"department\", fill_value=0))","metadata":{},"cell_type":"code","id":"53261e96-7b58-48e1-87f4-293867fb73a3","execution_count":null,"outputs":[]},{"source":"# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols\nprint(sales.pivot_table(values=\"weekly_sales\", index=\"department\", columns=\"type\", fill_value= 0, margins=True ))","metadata":{},"cell_type":"code","id":"ca02e32f-2dd8-4ee2-b37c-45dda4804385","execution_count":null,"outputs":[]},{"source":"# Slicing and indexing DataFrames ","metadata":{},"cell_type":"markdown","id":"61dd1985-5586-48ef-9035-82fc349eb472"},{"source":"**Setting and removing index**","metadata":{},"cell_type":"markdown","id":"0ba1b910-fea9-4df0-a106-f097b243083b"},{"source":"# Set the index of temperatures to city\ntemperatures_ind = temperatures.set_index(\"city\")\n\n# Look at temperatures_ind\nprint(temperatures_ind)\n\n# Reset the temperatures_ind index, keeping its contents\nprint(temperatures_ind.reset_index())\n\n# Reset the temperatures_ind index, dropping its contents\nprint(temperatures_ind.reset_index(drop=True))","metadata":{},"cell_type":"code","id":"39ca5750-055f-4fbf-96dc-98e1fb7c5dda","execution_count":null,"outputs":[]},{"source":"**Subsetting with loc**","metadata":{},"cell_type":"markdown","id":"ed9fb1d2-212e-4fe7-b90e-a2b604e4a1bd"},{"source":"# Make a list of cities to subset on\ncities = [\"Moscow\", \"Saint Petersburg\"]\n\n# Subset temperatures using square brackets\nprint(temperatures[temperatures[\"city\"].isin(cities)])\n\n# Subset temperatures_ind using .loc[]\nprint(temperatures_ind.loc[cities])","metadata":{},"cell_type":"code","id":"a1fc3be5-880e-454a-bdaa-941df0e41dbc","execution_count":null,"outputs":[]},{"source":"**Setting mulyi indexing \".set_index\"**","metadata":{},"cell_type":"markdown","id":"539d4272-9988-43b7-a648-fa8858188c1f"},{"source":"# Index temperatures by country & city\ntemperatures_ind= temperatures.set_index([\"country\", \"city\"])\n\n# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\nrows_to_keep = [(\"Brazil\",\"Rio De Janeiro\"), (\"Pakistan\",\"Lahore\")]\n\n# Subset for rows to keep\nprint(temperatures_ind.loc[rows_to_keep])\n\nprint(type(temperatures))","metadata":{},"cell_type":"code","id":"df9f802c-1eb7-4d29-96c8-c52aecd2a1ab","execution_count":null,"outputs":[]},{"source":"**Sorting by index value \".sort_index\"**","metadata":{},"cell_type":"markdown","id":"02da7db5-6c3f-4fa2-942c-29a14fedbbf3"},{"source":"# Sort temperatures_ind by index values\nprint(temperatures_ind.sort_index())\n\n# Sort temperatures_ind by index values at the city level\nprint(temperatures_ind.sort_index(level= \"city\"))\n\n# Sort temperatures_ind by country then descending city\nprint(temperatures_ind.sort_index(level= [\"country\",\"city\"], ascending=[True,False]))","metadata":{},"cell_type":"code","id":"59a579d5-1b57-42c4-bff2-8af2bf1aa662","execution_count":null,"outputs":[]},{"source":"# Sort the index of temperatures_ind\ntemperatures_srt = temperatures_ind.sort_index()\n\n# Subset rows from Pakistan to Russia\nprint(temperatures_srt.loc[\"Pakistan\": \"Russia\"])\n\n# Try to subset rows from Lahore to Moscow\nprint(temperatures_srt.loc[\"Lahore\": \"Moscow\"])\n\n# Subset rows from Pakistan, Lahore to Russia, Moscow\nprint(temperatures_srt.loc[(\"Pakistan\", \"Lahore\"):(\"Russia\", \"Moscow\")])","metadata":{},"cell_type":"code","id":"1a1cac82-b798-4e4f-970f-f85d5b712982","execution_count":null,"outputs":[]},{"source":"# Subset rows from India, Hyderabad to Iraq, Baghdad\nprint(temperatures_srt.loc[(\"India\", \"Hyderabad\"): (\"Iraq\", \"Baghdad\")])\n\n# Subset columns from date to avg_temp_c\nprint(temperatures_srt.loc[:, \"date\": \"avg_temp_c\"])\n\n# Subset in both directions at once\nprint(temperatures_srt.loc[(\"India\", \"Hyderabad\"): (\"Iraq\", \"Baghdad\"), \"date\": \"avg_temp_c\"])","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1700244495635,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"cell_type":"code","id":"16d999fc-1415-4cbf-8d11-dfcd86527c4e","execution_count":0,"outputs":[]},{"source":"**slicing time series**","metadata":{},"cell_type":"markdown","id":"32c9703d-a720-41c2-8b02-faa21b127994"},{"source":"# Use Boolean conditions to subset temperatures for rows in 2010 and 2011\ntemperatures_bool = temperatures[(temperatures[\"date\"] >= \"2010-01-01\") & (temperatures[\"date\"] <= \"2011-12-31\")]\n\nprint(temperatures_bool)\n\n# Set date as the index and sort the index\ntemperatures_ind = temperatures.set_index(\"date\").sort_index()\n\n# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\nprint(temperatures_ind.loc[\"2010\":\"2011\"])\n\n# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\nprint(temperatures_ind.loc[\"2010-08\":\"2011-02\"])","metadata":{},"cell_type":"code","id":"43ce4114-1264-4ee7-9dd6-96a278b1ab44","execution_count":null,"outputs":[]},{"source":"**Subsetting by row/column**","metadata":{},"cell_type":"markdown","id":"0594cf8b-f7d2-44c8-9b8b-37bb6c203189"},{"source":"# Get 23rd row, 2nd column (index 22, 1)\nprint(temperatures.iloc[22:1])\n\n# Use slicing to get the first 5 rows\nprint(temperatures.iloc[0:5,:])\n# Use slicing to get columns 3 to 4\nprint(temperatures.iloc[: , 2:4])\n\n# Use slicing in both directions at once\nprint(temperatures.iloc[0:5, 2:4]) ","metadata":{},"cell_type":"code","id":"e417b50d-82ae-4d52-9a26-94eab08ab339","execution_count":null,"outputs":[]},{"source":"**Pivot temperature**","metadata":{},"cell_type":"markdown","id":"4529d493-da7e-4e87-b758-ab4cb34179a6"},{"source":"# Add a year column to temperatures\ntemperatures[\"year\"]= temperatures[\"date\"].dt.year\n\n# Pivot avg_temp_c by country and city vs year\ntemp_by_country_city_vs_year = temperatures.pivot_table( values= \"avg_temp_c\" , index=[\"country\", \"city\"], columns= \"year\")\n\n# See the result\nprint(temp_by_country_city_vs_year)","metadata":{},"cell_type":"code","id":"5fb3e5f6-28be-423e-84a7-214bc4fe6b8e","execution_count":null,"outputs":[]},{"source":"**Subsetting pivot tables**","metadata":{},"cell_type":"markdown","id":"7fca03c8-a83c-4311-adb2-ce20fbb29abc"},{"source":"# Subset for Egypt to India\ntemp_by_country_city_vs_year.loc[\"Egypt\": \"India\"]\n\n# Subset for Egypt, Cairo to India, Delhi\ntemp_by_country_city_vs_year.loc[(\"Egypt\", \"Cairo\"):(\"India\", \"Delhi\")]\n\n# Subset for Egypt, Cairo to India, Delhi, and 2005 to 2010\ntemp_by_country_city_vs_year.loc[(\"Egypt\", \"Cairo\"):(\"India\", \"Delhi\"), \"2005\": \"2010\"]","metadata":{},"cell_type":"code","id":"97c74469-8ca4-4801-aad0-df102931936f","execution_count":null,"outputs":[]},{"source":"**Calculating on a pivot table**","metadata":{},"cell_type":"markdown","id":"e8668089-7d49-4b3d-a583-ea6c6508c8ab"},{"source":"# Get the worldwide mean temp by year\nmean_temp_by_year = temp_by_country_city_vs_year.mean(axis=\"index\")\n\n# Get the mean temp by city\nmean_temp_by_city = temp_by_country_city_vs_year.mean(axis=\"columns\")\n\n# Filter for the year that had the highest mean temp\nprint(mean_temp_by_year[mean_temp_by_year == mean_temp_by_year.max()])\n\n# Filter for the city that had the lowest mean temp\nprint(mean_temp_by_city[mean_temp_by_city == mean_temp_by_city.min()])","metadata":{},"cell_type":"code","id":"31e29f62-5465-42d7-bc53-1976fd6e7a1a","execution_count":null,"outputs":[]},{"source":"# Creating and Visualization DataFrames","metadata":{},"cell_type":"markdown","id":"50e25f8a-6caf-4dbe-b97b-7335b4f23082"},{"source":"**Bar plot**","metadata":{},"cell_type":"markdown","id":"752fb1e3-84b4-4ddb-9591-855294311614"},{"source":"# Import matplotlib.pyplot with alias plt\nimport matplotlib.pyplot as plt\n\n# Look at the first few rows of data\nprint(avocados.head())\n\n# Get the total number of avocados sold of each size\nnb_sold_by_size = avocados.groupby(\"size\")[\"nb_sold\"].sum()\n\n# Create a bar plot of the number of avocados sold by size\nnb_sold_by_size.plot(kind= \"bar\", color= \"magenta\")\n\n# Show the plot\nplt.show()","metadata":{},"cell_type":"code","id":"f12d3ee4-7245-400a-be6e-0e7844e43111","execution_count":null,"outputs":[]},{"source":"**Scatter Plot**","metadata":{},"cell_type":"markdown","id":"ff52bed8-5d37-4277-aed1-7e45ea775407"},{"source":"# Scatter plot of avg_price vs. nb_sold with title\navocados.plot(x=\"nb_sold\", y=\"avg_price\", kind= \"scatter\",\ntitle=\"Number of avocados sold vs. average price\")\n\n# Show the plot\nplt.show()","metadata":{},"cell_type":"code","id":"b1bc54eb-5805-4114-b620-04b5c5d2b8df","execution_count":null,"outputs":[]},{"source":"**Histogram 2 variables**","metadata":{},"cell_type":"markdown","id":"238c04c2-76c6-4186-ab4c-e19b50f537e0"},{"source":"# Modify bins to 20\navocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5, bins=20)\n\n# Modify bins to 20\navocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5, bins=20)\n\n# Add a legend\nplt.legend([\"conventional\", \"organic\"])\n\n# Show the plot\nplt.show()","metadata":{},"cell_type":"code","id":"3a98c9ad-9cd6-4599-a7d6-585e274344e5","execution_count":null,"outputs":[]},{"source":"**Finding Missing values**","metadata":{},"cell_type":"markdown","id":"1ddf7daa-7428-412f-8370-fcdfc5077220"},{"source":"# Import matplotlib.pyplot with alias plt\nimport matplotlib.pyplot as plt\n\n# Check individual values for missing values\nprint(avocados_2016.isna())\n\n# Check each column for missing values\nprint(avocados_2016.isna().any())\n\n# Bar plot of missing values by variable\navocados_2016.isna().sum().plot(kind= \"bar\")\n\n# Show plot\nplt.show()","metadata":{},"cell_type":"code","id":"d30caca2-a998-423a-a305-44b73ee7b93c","execution_count":null,"outputs":[]},{"source":"**Dropping rows with missing values**","metadata":{},"cell_type":"markdown","id":"23b3c152-4817-4d60-93ee-c35167d2a460"},{"source":"# Remove rows with missing values\navocados_complete = avocados_2016.dropna()\n\n# Check if any columns contain missing values\nprint(avocados_complete.isna().any())","metadata":{},"cell_type":"code","id":"c95b4d56-c910-4df9-b252-2cc0fe7325b6","execution_count":null,"outputs":[]},{"source":"**Replacing missing values**","metadata":{},"cell_type":"markdown","id":"f84b3e85-4fae-42bc-b645-dfddfe692245"},{"source":"# From previous step\ncols_with_missing = [\"small_sold\", \"large_sold\", \"xl_sold\"]\navocados_2016[cols_with_missing].hist()\nplt.show()\n\n# Fill in missing values with 0\navocados_filled = avocados_2016.fillna(0)\n\n# Create histograms of the filled columns\navocados_filled[cols_with_missing].hist()\n\n# Show the plot\nplt.show()","metadata":{},"cell_type":"code","id":"559e57d1-ecdf-4c83-9614-d4167a2aef10","execution_count":null,"outputs":[]},{"source":"## Creating Data Frames","metadata":{},"cell_type":"markdown","id":"b5c66db3-28ee-4a8b-96a7-e87eeaf288da"},{"source":"**From a list of dictionaries** _(by row)_ ","metadata":{},"cell_type":"markdown","id":"c42a5dac-6b0a-4839-b3b2-54a7a965b05b"},{"source":"# Create a list of dictionaries with new data\navocados_list = [\n    {\"date\": \"2019-11-03\", \"small_sold\": 10376832, \"large_sold\": 7835071},\n    {\"date\": \"2019-11-10\", \"small_sold\": 10717154, \"large_sold\": 8561348},\n]\n\n# Convert list into DataFrame\navocados_2019 = pd.DataFrame(avocados_list)\n\n# Print the new DataFrame\nprint(avocados_2019)","metadata":{},"cell_type":"code","id":"d10135bd-eee9-49fb-bfb7-a8f39b886235","execution_count":null,"outputs":[]},{"source":"**From a dictionary of lists**","metadata":{},"cell_type":"markdown","id":"c917ad94-7110-4b13-8a23-8d53feca3157"},{"source":"# Create a dictionary of lists with new data\navocados_dict = {\n  \"date\": [\"2019-11-17\", \"2019-12-01\"],\n  \"small_sold\": [10859987, 9291631],\n  \"large_sold\": [7674135, 6238096]\n}\n\n# Convert dictionary into DataFrame\navocados_2019 = pd.DataFrame(avocados_dict)\n\n# Print the new DataFrame\nprint(avocados_2019)","metadata":{},"cell_type":"code","id":"b47a660e-a2a3-4bed-86f6-32712de2adb7","execution_count":null,"outputs":[]},{"source":"**CVS to Data Frame**","metadata":{},"cell_type":"markdown","id":"d974c24b-5995-451f-b36f-03fae588af3d"},{"source":"# Read CSV as DataFrame called airline_bumping\nairline_bumping = pd.read_csv(\"airline_bumping.csv\")\n\n# Take a look at the DataFrame\nprint(airline_bumping.head())","metadata":{},"cell_type":"code","id":"7495c3c7-a829-4f4b-88fb-8e69aa88dc2e","execution_count":null,"outputs":[]},{"source":"**Data Frame to CSV** _(sorting)_","metadata":{},"cell_type":"markdown","id":"51894a47-f285-44fc-8202-d8b716f456cb"},{"source":"# Create airline_totals_sorted\nairline_totals_sorted = airline_totals.sort_values(\"bumps_per_10k\", ascending= False)\n\n# Print airline_totals_sorted\nprint(airline_totals_sorted)\n\n# Save as airline_totals_sorted.csv\n\nairline_totals_sorted.to_csv(\"airline_totals_sorted.csv\")","metadata":{},"cell_type":"code","id":"caf73420-6460-4abf-a54e-fee9653fd09a","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}